"""
Task Executor v1

Executes tasks from backlog by generating/modifying files according to task spec.
Enforces allowed_paths strictly and dispatches by scope.
"""

from dataclasses import dataclass
from pathlib import Path
from typing import List, Dict, Any
import os


@dataclass
class ExecResult:
    """Result of task execution."""
    success: bool
    changed_files: List[str]  # Relative paths from repo root
    error: str = ""


class PathViolationError(Exception):
    """Raised when task attempts to write outside allowed_paths."""
    pass


def validate_output_path(file_path: str, allowed_paths: List[str], repo_root: str) -> None:
    """
    Validate that file_path is within allowed_paths.
    
    Args:
        file_path: Absolute or relative path to validate
        allowed_paths: List of allowed path prefixes (e.g., ["docs/", ".leviathan/"])
        repo_root: Absolute path to repository root
        
    Raises:
        PathViolationError: If file_path is outside allowed_paths
    """
    # Convert to relative path from repo root
    abs_path = Path(file_path)
    if not abs_path.is_absolute():
        abs_path = Path(repo_root) / file_path
    
    try:
        rel_path = abs_path.relative_to(repo_root)
    except ValueError:
        raise PathViolationError(f"Path {file_path} is outside repository root")
    
    # Check if path starts with any allowed prefix
    rel_path_str = str(rel_path)
    for allowed in allowed_paths:
        if rel_path_str.startswith(allowed.rstrip('/')):
            return
    
    raise PathViolationError(
        f"Path {rel_path_str} is outside allowed_paths: {allowed_paths}"
    )


def _determine_output_file_path(allowed_paths: List[str], task_id: str) -> str:
    """
    Determine output file path from allowed_paths.
    
    Rules:
    1. If allowed_paths contains exactly one .md file path, use it
    2. If allowed_paths contains only directories, generate deterministic filename
    3. Otherwise, fail with clear error
    
    Args:
        allowed_paths: List of allowed path patterns
        task_id: Task identifier for deterministic naming
        
    Returns:
        Relative file path from repo root
        
    Raises:
        ValueError: If output path cannot be determined
    """
    if not allowed_paths:
        raise ValueError("allowed_paths is empty, cannot determine output file")
    
    # Check for explicit .md file paths
    md_files = [p for p in allowed_paths if p.endswith('.md')]
    
    if len(md_files) == 1:
        # Explicit single markdown file
        return md_files[0]
    elif len(md_files) > 1:
        raise ValueError(
            f"Multiple markdown files in allowed_paths: {md_files}. "
            "Specify exactly one output file."
        )
    
    # All paths are directories - generate deterministic filename
    # Use first directory and convert task_id to filename
    base_dir = allowed_paths[0].rstrip('/')
    filename = task_id.upper().replace('-', '_') + '.md'
    return f"{base_dir}/{filename}"


def _generate_doc_content(task_spec: Dict[str, Any]) -> str:
    """
    Generate markdown documentation content from task specification.
    
    Args:
        task_spec: Task specification from backlog
        
    Returns:
        Markdown content as string
    """
    task_id = task_spec.get('id', 'unknown')
    title = task_spec.get('title', 'Untitled')
    acceptance_criteria = task_spec.get('acceptance_criteria', [])
    scope = task_spec.get('scope', 'unknown')
    
    # Build markdown content
    lines = []
    lines.append(f"# {title}")
    lines.append("")
    lines.append("## Metadata")
    lines.append("")
    lines.append(f"- **Task ID**: `{task_id}`")
    lines.append(f"- **Scope**: {scope}")
    lines.append(f"- **Generated**: Leviathan Autonomy v1")
    lines.append("")
    
    # Add sections based on acceptance criteria
    if acceptance_criteria:
        lines.append("## Overview")
        lines.append("")
        lines.append("This document addresses the following requirements:")
        lines.append("")
        for criterion in acceptance_criteria:
            lines.append(f"- {criterion}")
        lines.append("")
    
    # Add content sections based on task type
    allowed_paths = task_spec.get('allowed_paths', [])
    is_template = (
        'template' in task_id or 
        'template' in title.lower() or 
        any('templates/' in path for path in allowed_paths)
    )
    
    if is_template:
        lines.extend(_generate_template_content(task_spec))
    elif 'operating-rules' in task_id or 'rules' in title.lower():
        lines.extend(_generate_operating_rules_content(task_spec))
    elif 'runbook' in task_id or 'runbook' in title.lower():
        lines.extend(_generate_runbook_content(task_spec))
    else:
        lines.extend(_generate_generic_doc_content(task_spec))
    
    lines.append("")
    lines.append("---")
    lines.append("")
    lines.append(f"*Generated by Leviathan Autonomy for task `{task_id}`*")
    lines.append("")
    
    return "\n".join(lines)


def _generate_template_content(task_spec: Dict[str, Any]) -> List[str]:
    """Generate content for template documents (e.g., PR templates)."""
    lines = []
    task_id = task_spec.get('id', 'unknown')
    acceptance_criteria = task_spec.get('acceptance_criteria', [])
    allowed_paths = task_spec.get('allowed_paths', [])
    scope = task_spec.get('scope', 'unknown')
    
    # Detect if this is a PR template
    is_pr_template = 'pr' in task_id.lower() or any('pr' in criterion.lower() for criterion in acceptance_criteria)
    
    if is_pr_template:
        lines.append("## Task Information")
        lines.append("")
        lines.append("**Task ID:** `<TASK_ID>`")
        lines.append("")
        lines.append("**Attempt ID:** `<ATTEMPT_ID>`")
        lines.append("")
        lines.append("## Scope")
        lines.append("")
        lines.append(f"**Scope:** `{scope}`")
        lines.append("")
        lines.append("**Allowed Paths:**")
        if allowed_paths:
            for path in allowed_paths:
                lines.append(f"- `{path}`")
        else:
            lines.append("- All paths (use with caution)")
        lines.append("")
        lines.append("## Summary")
        lines.append("")
        lines.append("<!-- Brief description of what this PR does -->")
        lines.append("")
        lines.append("<SUMMARY>")
        lines.append("")
        lines.append("## Acceptance Criteria")
        lines.append("")
        if acceptance_criteria:
            for criterion in acceptance_criteria:
                lines.append(f"- [ ] {criterion}")
        else:
            lines.append("- [ ] Task requirements met")
        lines.append("")
        lines.append("## Testing / Evidence")
        lines.append("")
        lines.append("**Commands run:**")
        lines.append("```bash")
        lines.append("# Add commands used to verify changes")
        lines.append("<COMMANDS>")
        lines.append("```")
        lines.append("")
        lines.append("**Expected output:**")
        lines.append("```")
        lines.append("<EXPECTED_OUTPUT>")
        lines.append("```")
        lines.append("")
        lines.append("**Actual output:**")
        lines.append("```")
        lines.append("<ACTUAL_OUTPUT>")
        lines.append("```")
        lines.append("")
        lines.append("## Risk Assessment")
        lines.append("")
        lines.append("**Risk Level:** `<low|medium|high>`")
        lines.append("")
        lines.append("**Potential Impact:**")
        lines.append("- <IMPACT_DESCRIPTION>")
        lines.append("")
        lines.append("**Rollback Plan:**")
        lines.append("```bash")
        lines.append("# Commands to rollback if needed")
        lines.append("<ROLLBACK_COMMANDS>")
        lines.append("```")
        lines.append("")
        lines.append("## Links")
        lines.append("")
        lines.append("- **Control Plane:** `<CONTROL_PLANE_URL>`")
        lines.append("- **Console:** `<CONSOLE_URL>`")
        lines.append("- **Backlog Task:** `.leviathan/backlog.yaml#<TASK_ID>`")
        lines.append("")
    else:
        # Generic template content
        lines.append("## Template Structure")
        lines.append("")
        lines.append("This template provides a structured format for:")
        lines.append("")
        if acceptance_criteria:
            for criterion in acceptance_criteria:
                lines.append(f"- {criterion}")
        lines.append("")
        lines.append("## Usage")
        lines.append("")
        lines.append("Replace placeholders marked with `<PLACEHOLDER>` with actual values.")
        lines.append("")
        lines.append("## Sections")
        lines.append("")
        if acceptance_criteria:
            for i, criterion in enumerate(acceptance_criteria, 1):
                lines.append(f"### {i}. {criterion}")
                lines.append("")
                lines.append("<CONTENT>")
                lines.append("")
    
    return lines


def _generate_operating_rules_content(task_spec: Dict[str, Any]) -> List[str]:
    """Generate content for operating rules documents."""
    lines = []
    lines.append("## Operating Rules")
    lines.append("")
    lines.append("### Max Open PRs Rule")
    lines.append("")
    lines.append("**Limit**: 2 open PRs maximum")
    lines.append("")
    lines.append("**Rationale**:")
    lines.append("- Prevents runaway PR creation")
    lines.append("- Ensures human review capacity is not overwhelmed")
    lines.append("- Maintains quality over quantity")
    lines.append("- Allows for focused review and iteration")
    lines.append("")
    lines.append("### Single-Scope PR Requirement")
    lines.append("")
    lines.append("Each PR must modify files within a single scope (e.g., docs/, tests/, .leviathan/).")
    lines.append("")
    lines.append("**Benefits**:")
    lines.append("- Easier to review")
    lines.append("- Clearer intent")
    lines.append("- Reduced merge conflicts")
    lines.append("- Simpler rollback if needed")
    lines.append("")
    lines.append("### allowed_paths Enforcement")
    lines.append("")
    lines.append("Every task must declare `allowed_paths` - the file/directory prefixes it may modify.")
    lines.append("")
    lines.append("**Enforcement**:")
    lines.append("- Executor validates all writes before execution")
    lines.append("- Writes outside allowed_paths raise `PathViolationError`")
    lines.append("- Task fails immediately on violation")
    lines.append("- No partial writes committed")
    lines.append("")
    lines.append("### Dependency Resolution Rules")
    lines.append("")
    lines.append("Tasks may declare dependencies on other tasks via `dependencies` field.")
    lines.append("")
    lines.append("**Rules** (v1 conservative):")
    lines.append("- Scheduler skips tasks with any dependencies")
    lines.append("- Dependencies must be removed manually once satisfied")
    lines.append("- Future: automatic dependency resolution based on completion status")
    lines.append("")
    lines.append("### Task Completion Criteria")
    lines.append("")
    lines.append("A task is considered complete when:")
    lines.append("")
    lines.append("1. Worker executes task successfully")
    lines.append("2. Worker marks task `status: completed` in backlog")
    lines.append("3. Worker creates PR with changes + backlog update")
    lines.append("4. PR is reviewed and merged to main")
    lines.append("5. Scheduler fetches updated backlog and skips completed task")
    lines.append("")
    lines.append("**Backlog Status Writeback**:")
    lines.append("- Worker updates `.leviathan/backlog.yaml` in same PR")
    lines.append("- Sets `ready: false` and `status: completed`")
    lines.append("- Records `last_attempt_id`, `branch_name`, `completed_at`")
    lines.append("- Prevents infinite reruns")
    lines.append("")
    lines.append("### How to Mark Tasks ready:true")
    lines.append("")
    lines.append("Before setting `ready: true`:")
    lines.append("")
    lines.append("1. Ensure acceptance criteria are clear and testable")
    lines.append("2. Set `allowed_paths` as narrow as possible")
    lines.append("3. Verify `estimated_size` ≤ m (or decompose task)")
    lines.append("4. Remove or satisfy all dependencies")
    lines.append("5. Confirm scope matches autonomy `allowed_path_prefixes`")
    lines.append("6. Verify task is idempotent (safe to retry)")
    lines.append("")
    return lines


def _generate_runbook_content(task_spec: Dict[str, Any]) -> List[str]:
    """Generate content for runbook documents."""
    lines = []
    lines.append("## Purpose")
    lines.append("")
    lines.append("This runbook provides operational guidance for the system.")
    lines.append("")
    lines.append("## Prerequisites")
    lines.append("")
    lines.append("- Access to the system")
    lines.append("- Required credentials configured")
    lines.append("- Understanding of system architecture")
    lines.append("")
    lines.append("## Procedures")
    lines.append("")
    
    acceptance_criteria = task_spec.get('acceptance_criteria', [])
    for i, criterion in enumerate(acceptance_criteria, 1):
        lines.append(f"### {i}. {criterion}")
        lines.append("")
        lines.append("**Steps**:")
        lines.append("")
        lines.append("1. [Step details to be added]")
        lines.append("2. [Step details to be added]")
        lines.append("")
    
    lines.append("## Troubleshooting")
    lines.append("")
    lines.append("### Common Issues")
    lines.append("")
    lines.append("**Issue**: [Description]")
    lines.append("")
    lines.append("**Solution**: [Resolution steps]")
    lines.append("")
    return lines


def _generate_generic_doc_content(task_spec: Dict[str, Any]) -> List[str]:
    """Generate generic documentation content."""
    lines = []
    lines.append("## Description")
    lines.append("")
    lines.append("This document provides information as specified in the acceptance criteria.")
    lines.append("")
    
    acceptance_criteria = task_spec.get('acceptance_criteria', [])
    for i, criterion in enumerate(acceptance_criteria, 1):
        lines.append(f"### {i}. {criterion}")
        lines.append("")
        lines.append("[Content to be added]")
        lines.append("")
    
    return lines


def execute_docs_task(task_id: str, task_spec: Dict[str, Any], repo_path: str) -> ExecResult:
    """
    Execute a docs-scope task (generic handler).
    
    Determines output file path from allowed_paths and generates markdown content
    from task specification (title, acceptance criteria).
    
    Args:
        task_id: Task identifier
        task_spec: Task specification from backlog
        repo_path: Absolute path to repository
        
    Returns:
        ExecResult with success status and changed files
    """
    allowed_paths = task_spec.get('allowed_paths', [])
    
    # Determine output file path
    try:
        output_path = _determine_output_file_path(allowed_paths, task_id)
    except ValueError as e:
        return ExecResult(success=False, changed_files=[], error=str(e))
    
    # Validate path
    try:
        validate_output_path(output_path, allowed_paths, repo_path)
    except PathViolationError as e:
        return ExecResult(success=False, changed_files=[], error=str(e))
    
    # Generate content
    content = _generate_doc_content(task_spec)
    
    # Write file
    abs_output_path = Path(repo_path) / output_path
    abs_output_path.parent.mkdir(parents=True, exist_ok=True)
    
    # Check if file already exists with same content (idempotency)
    if abs_output_path.exists():
        existing_content = abs_output_path.read_text()
        if existing_content == content:
            # No changes needed
            return ExecResult(success=True, changed_files=[], error="")
    
    abs_output_path.write_text(content)
    
    return ExecResult(
        success=True,
        changed_files=[output_path],
        error=""
    )


def _execute_backlog_guide_legacy(task_spec: Dict[str, Any], repo_path: str, allowed_paths: List[str]) -> ExecResult:
    """Legacy handler for docs-leviathan-backlog-guide (preserved for reference)."""
    
    output_path = "docs/27_RADIX_BACKLOG_AUTONOMY_GUIDE.md"
    
    # Validate path
    try:
        validate_output_path(output_path, allowed_paths, repo_path)
    except PathViolationError as e:
        return ExecResult(success=False, changed_files=[], error=str(e))
    
    content = """# Radix Backlog Autonomy Guide

## Purpose

This document defines the backlog discipline for Leviathan autonomous execution in the Radix project. It ensures tasks are well-specified, bounded, and safe for autonomous agents to execute without human intervention.

## Required Task Fields

Every task in `.leviathan/backlog.yaml` must include:

### Core Fields
- **id**: Unique task identifier (kebab-case)
- **title**: Human-readable task description
- **scope**: Task category (see Scope Taxonomy below)
- **priority**: high | medium | low
- **ready**: true | false (whether task is executable)
- **allowed_paths**: List of path prefixes the task may modify
- **acceptance_criteria**: List of concrete success conditions
- **dependencies**: List of task IDs that must complete first
- **estimated_size**: xs | s | m | l | xl (rewrite threshold guidance)

### Optional Fields
- **status**: pending | in_progress | completed
- **pr_number**: GitHub PR number (if completed)
- **branch_name**: Git branch name (if in progress or completed)
- **commit**: Git commit SHA (if completed)

## Scope Taxonomy

Tasks are categorized by scope to enable targeted execution:

- **docs**: Documentation changes only
- **tests**: Test file changes only
- **ci**: CI/CD workflow changes
- **bootstrap**: Initial repository setup/indexing
- **tools**: Developer tooling and scripts
- **infra**: Infrastructure configuration

## allowed_paths Discipline

The `allowed_paths` field is **critical for safety**. It restricts what files a task may modify.

### Rules
1. **Empty list `[]`** means task can modify any file (use sparingly, requires review)
2. **Specific paths** limit task to those prefixes (e.g., `["docs/"]`)
3. **Multiple paths** allowed (e.g., `["docs/", "tests/schemas/"]`)
4. **Trailing slashes** recommended for directories
5. **Enforcement**: Executor validates all writes against allowed_paths before execution

### Examples

**Docs-only task:**
```yaml
- id: api-docs-update
  scope: docs
  allowed_paths:
    - docs/api/
  acceptance_criteria:
    - Update docs/api/endpoints.md with new /v2/search endpoint
```

**Tests-only task:**
```yaml
- id: smoke-artifact-schema
  scope: tests
  allowed_paths:
    - tests/unit/test_research_async_smoke_artifact.py
    - tests/schemas/smoke_artifact_schema.json
  acceptance_criteria:
    - JSON schema defined for smoke artifact structure
    - Unit test validates artifact against schema
```

## Rewrite Threshold Management

The `estimated_size` field helps keep tasks under Leviathan's rewrite threshold (~300 lines).

### Size Guidelines
- **xs**: < 50 lines (single file, small change)
- **s**: 50-150 lines (1-2 files, focused change)
- **m**: 150-300 lines (multiple files, moderate scope)
- **l**: 300-500 lines (large change, may need splitting)
- **xl**: > 500 lines (requires decomposition into smaller tasks)

### Best Practices
1. Prefer **s** and **m** sized tasks for autonomous execution
2. Split **l** and **xl** tasks into smaller subtasks with dependencies
3. Use acceptance criteria to bound scope explicitly
4. If a task grows beyond estimate, mark as blocked and decompose

## Autonomy Guardrails

Leviathan operates under strict guardrails defined in `.leviathan/policy.yaml` and autonomy config:

### DEV Environment Guardrails
- **allowed_path_prefixes**: `[.leviathan/, docs/]` (only these scopes executable)
- **max_open_prs**: 1 (prevents runaway PR creation)
- **max_running_attempts**: 1 (one task at a time)
- **max_attempts_per_task**: 2 (retry limit)
- **circuit_breaker_failures**: 2 (stops after consecutive failures)

### Execution Flow
1. Scheduler selects task with `ready: true`
2. Validates task scope matches `allowed_path_prefixes`
3. Creates worker job with task spec
4. Worker executes task, validates all writes against `allowed_paths`
5. Worker creates PR (no auto-merge)
6. Human reviews and merges PR
7. Scheduler continues with next ready task

### Safety Mechanisms
- **No direct pushes**: All changes via PR
- **No auto-merge**: Human approval required
- **Path enforcement**: Writes outside allowed_paths fail immediately
- **Event auditing**: All attempts logged to control plane
- **Deterministic**: Same task + same repo state = same output

## Task Readiness Checklist

Before setting `ready: true`:

- [ ] Task has clear, testable acceptance criteria
- [ ] `allowed_paths` is as narrow as possible
- [ ] `estimated_size` is ≤ m (or task is decomposed)
- [ ] Dependencies are satisfied or empty
- [ ] Scope matches current `allowed_path_prefixes` in autonomy config
- [ ] Task is idempotent (can be retried safely)

## Examples

### Example 1: Docs-Only Task

```yaml
- id: async-smoke-evidence-doc
  title: Add async smoke evidence documentation
  scope: docs
  priority: low
  ready: true
  allowed_paths:
    - docs/ci/ASYNC_SMOKE_EVIDENCE.md
  acceptance_criteria:
    - Documents smoke artifact JSON structure
    - Explains success vs failure artifacts
    - Shows example artifacts for each case
    - Links to workflow and script files
  dependencies:
    - smoke-artifact-schema
  estimated_size: xs
```

### Example 2: Tests-Only Task

```yaml
- id: api-base-normalization-test
  title: Add API base normalization unit test
  scope: tests
  priority: medium
  ready: false
  allowed_paths:
    - tests/unit/test_sentinel_api_base_normalization.py
  acceptance_criteria:
    - Test validates API base URL normalization logic
    - Covers missing stage path detection and correction
    - Covers trailing slash removal
    - Covers already-normalized URLs (no-op)
  dependencies:
    - smoke-trigger-tighten
  estimated_size: xs
```

## References

- Backlog format: `.leviathan/backlog.yaml`
- Autonomy policy: `.leviathan/policy.yaml`
- Autonomy config: `ops/autonomy/dev.yaml`
- Execution logs: Control plane event store

---

**Document Status**: Living document, updated as backlog discipline evolves.
"""
    
    # Write file
    abs_output_path = Path(repo_path) / output_path
    abs_output_path.parent.mkdir(parents=True, exist_ok=True)
    
    # Check if file already exists with same content
    if abs_output_path.exists():
        existing_content = abs_output_path.read_text()
        if existing_content == content:
            # No changes needed
            return ExecResult(success=True, changed_files=[], error="")
    
    abs_output_path.write_text(content)
    
    return ExecResult(
        success=True,
        changed_files=[output_path],
        error=""
    )


def _determine_test_output_path(allowed_paths: List[str], task_id: str) -> str:
    """
    Determine output test file path from allowed_paths.
    
    Rules:
    1. If allowed_paths contains exactly one .py file path, use it
    2. If allowed_paths contains only directories, generate deterministic filename
    3. Otherwise, fail with clear error
    
    Args:
        allowed_paths: List of allowed path patterns
        task_id: Task identifier for deterministic naming
        
    Returns:
        Relative file path from repo root
        
    Raises:
        ValueError: If output path cannot be determined
    """
    if not allowed_paths:
        raise ValueError("allowed_paths is empty, cannot determine output file")
    
    # Check for explicit .py file paths
    py_files = [p for p in allowed_paths if p.endswith('.py')]
    
    if len(py_files) == 1:
        # Explicit single Python file
        return py_files[0]
    elif len(py_files) > 1:
        raise ValueError(
            f"Multiple Python files in allowed_paths: {py_files}. "
            "Specify exactly one output file."
        )
    
    # All paths are directories - generate deterministic filename
    # Use first directory and convert task_id to test filename
    base_dir = allowed_paths[0].rstrip('/')
    # Convert task-id to test_task_id.py format
    filename = 'test_' + task_id.replace('-', '_') + '.py'
    return f"{base_dir}/{filename}"


def _generate_test_content(task_spec: Dict[str, Any]) -> str:
    """
    Generate pytest-style test content from task specification.
    
    Args:
        task_spec: Task specification from backlog
        
    Returns:
        Python test code as string
    """
    task_id = task_spec.get('id', 'unknown')
    title = task_spec.get('title', 'Untitled')
    acceptance_criteria = task_spec.get('acceptance_criteria', [])
    
    # Build Python test content
    lines = []
    lines.append('"""')
    lines.append(f"{title}")
    lines.append("")
    lines.append(f"Task ID: {task_id}")
    lines.append("Generated by Leviathan Autonomy v1")
    lines.append('"""')
    lines.append("")
    lines.append("import pytest")
    lines.append("")
    lines.append("")
    
    # Generate test functions from acceptance criteria
    if acceptance_criteria:
        for i, criterion in enumerate(acceptance_criteria, 1):
            # Convert criterion to function name
            func_name = criterion.lower()
            # Remove special chars and convert to snake_case
            func_name = ''.join(c if c.isalnum() or c.isspace() else ' ' for c in func_name)
            func_name = '_'.join(func_name.split()[:8])  # Limit length
            func_name = f"test_{func_name}"
            
            lines.append(f"def {func_name}():")
            lines.append(f'    """Test: {criterion}"""')
            lines.append(f"    # TODO: implement assertion for: {criterion}")
            lines.append('    assert True, "Test not yet implemented"')
            lines.append("")
            lines.append("")
    else:
        # No acceptance criteria - create a placeholder test
        lines.append(f"def test_{task_id.replace('-', '_')}():")
        lines.append(f'    """Test for {task_id}"""')
        lines.append("    # TODO: implement test logic")
        lines.append('    assert True, "Test not yet implemented"')
        lines.append("")
    
    return "\n".join(lines)


def execute_tests_task(task_id: str, task_spec: Dict[str, Any], repo_path: str) -> ExecResult:
    """
    Execute a tests task by generating test file.
    
    Args:
        task_id: Task identifier
        task_spec: Task specification from backlog
        repo_path: Absolute path to repository
        
    Returns:
        ExecResult with execution outcome
    """
    allowed_paths = task_spec.get('allowed_paths', [])
    
    # Determine output file path
    try:
        output_path = _determine_test_output_path(allowed_paths, task_id)
    except ValueError as e:
        return ExecResult(success=False, changed_files=[], error=str(e))
    
    # Validate output path
    try:
        validate_output_path(output_path, allowed_paths, repo_path)
    except PathViolationError as e:
        return ExecResult(success=False, changed_files=[], error=str(e))
    
    # Generate test content
    content = _generate_test_content(task_spec)
    
    # Write file
    abs_output_path = Path(repo_path) / output_path
    abs_output_path.parent.mkdir(parents=True, exist_ok=True)
    
    # Check if file already exists with same content (idempotency)
    if abs_output_path.exists():
        existing_content = abs_output_path.read_text()
        if existing_content == content:
            # No changes needed
            return ExecResult(success=True, changed_files=[], error="")
    
    abs_output_path.write_text(content)
    
    return ExecResult(
        success=True,
        changed_files=[output_path],
        error=""
    )


def execute_task(task_spec: Dict[str, Any], repo_path: str) -> ExecResult:
    """
    Execute a task based on its scope.
    
    Args:
        task_spec: Task specification from backlog
        repo_path: Absolute path to repository
        
    Returns:
        ExecResult with execution outcome
        
    Raises:
        NotImplementedError: If scope executor not implemented
    """
    task_id = task_spec.get('id', 'unknown')
    scope = task_spec.get('scope', 'unknown')
    
    if scope == 'docs':
        return execute_docs_task(task_id, task_spec, repo_path)
    elif scope in ['tests', 'test']:
        return execute_tests_task(task_id, task_spec, repo_path)
    else:
        raise NotImplementedError(f"No executor implemented for scope: {scope}")
